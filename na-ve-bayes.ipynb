{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-17T06:19:36.985131Z","iopub.execute_input":"2023-05-17T06:19:36.985478Z","iopub.status.idle":"2023-05-17T06:19:37.017720Z","shell.execute_reply.started":"2023-05-17T06:19:36.985450Z","shell.execute_reply":"2023-05-17T06:19:37.016591Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing, svm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nimport csv\nimport random\nimport math","metadata":{"execution":{"iopub.status.busy":"2023-05-17T07:19:38.718022Z","iopub.execute_input":"2023-05-17T07:19:38.718379Z","iopub.status.idle":"2023-05-17T07:19:38.723135Z","shell.execute_reply.started":"2023-05-17T07:19:38.718344Z","shell.execute_reply":"2023-05-17T07:19:38.722086Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"\ndef loadcsv(filename):\nlines = csv.reader(open(filename, \"r\"));\ndataset = list(lines)\nfor i in range(len(dataset)):\n #converting strings into numbers for processing\ndataset[i] = [float(x) for x in dataset[i]]\n\nreturn dataset\ndef splitdataset(dataset, splitratio):\n #67% training size\ntrainsize = int(len(dataset) * splitratio);\ntrainset = []\ncopy = list(dataset);\nwhile len(trainset) < trainsize:\n#generate indices for the dataset list randomly to pick ele for\ntraining data\nindex = random.randrange(len(copy));\ntrainset.append(copy.pop(index))\nreturn [trainset, copy]\ndef separatebyclass(dataset):\nseparated = {} #dictionary of classes 1 and 0\n#creates a dictionary of classes 1 and 0 where the values are\n#the instances belonging to each class\nfor i in range(len(dataset)):\nvector = dataset[i]\nif (vector[-1] not in separated):\nseparated[vector[-1]] = []\nseparated[vector[-1]].append(vector)\nreturn separated\ndef mean(numbers):\nreturn sum(numbers)/float(len(numbers))\ndef stdev(numbers):\navg = mean(numbers)\nvariance = sum([pow(x-avg,2) for x in\nnumbers])/float(len(numbers)-1)\nreturn math.sqrt(variance)\n\ndef summarize(dataset): #creates a dictionary of classes\nsummaries = [(mean(attribute), stdev(attribute)) for\nattribute in zip(*dataset)];\ndel summaries[-1] #excluding labels +ve or -ve\nreturn summaries\ndef summarizebyclass(dataset):\nseparated = separatebyclass(dataset);\n #print(separated)\nsummaries = {}\nfor classvalue, instances in separated.items():\n#for key,value in dic.items()\n#summaries is a dic of tuples(mean,std) for each class value\nsummaries[classvalue] = summarize(instances)\n#summarize is used to cal to mean and std\nreturn summaries\ndef calculateprobability(x, mean, stdev):\nexponent = math.exp(-(math.pow(x-mean,2)/\n(2*math.pow(stdev,2))))\nreturn (1 / (math.sqrt(2*math.pi) * stdev)) * exponent\ndef calculateclassprobabilities(summaries, inputvector):\n# probabilities contains the all prob of all class of test data\nprobabilities = {}\nfor classvalue, classsummaries in summaries.items():\n#class and attribute information as mean and sd\nprobabilities[classvalue] = 1\nfor i in range(len(classsummaries)):\nmean, stdev = classsummaries[i] #take mean and\nsd of every attribute for class 0 and 1 seperaely\nx = inputvector[i] #testvector's first attribute\nprobabilities[classvalue] *=\ncalculateprobability(x, mean, stdev);#use normal dist\nreturn probabilities\ndef predict(summaries, inputvector): #training and test data\nis passed\nprobabilities = calculateclassprobabilities(summaries,\ninputvector)\nbestLabel, bestProb = None, -1\nfor classvalue, probability in probabilities.items():\n#assigns that class which has the highest prob\nif bestLabel is None or probability > bestProb:\nbestProb = probability\nbestLabel = classvalue\nreturn bestLabel\n\ndef getpredictions(summaries, testset):\npredictions = []\nfor i in range(len(testset)):\nresult = predict(summaries, testset[i])\npredictions.append(result)\nreturn predictions\ndef getaccuracy(testset, predictions):\ncorrect = 0\nfor i in range(len(testset)):\nif testset[i][-1] == predictions[i]:\ncorrect += 1\nreturn (correct/float(len(testset))) * 100.0\ndef main():\nfilename = 'naivedata.csv'\nsplitratio = 0.67\ndataset = loadcsv(filename);\n\ntrainingset, testset = splitdataset(dataset, splitratio)\nprint('Split {0} rows into train={1} and test={2}\nrows'.format(len(dataset), len(trainingset), len(testset)))\n# prepare model\nsummaries = summarizebyclass(trainingset);\n#print(summaries)\n # test model\npredictions = getpredictions(summaries, testset) #find the\npredictions of test data with the training data\naccuracy = getaccuracy(testset, predictions)\nprint('Accuracy of the classifier is :\n{0}%'.format(accuracy))\n      \n      \n\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"main()","metadata":{},"execution_count":null,"outputs":[]}]}